---
order: -75
---

# LLM

=== Presentations
[!button icon="download" text="LLM Jailbreak Attacks"](/files/LLM_Jailbreak_Attacks.pdf)

=== Class Practice
- [GandalfAI](https://gandalf.lakera.ai/baseline) - Reveal the password, and advance through the levels.

=== Further Practice
- [Web LLMs Attacks](https://portswigger.net/web-security/llm-attacks)


=== References
- [Threats in LLM models](https://aivillage.org/large%20language%20models/threat-modeling-llm/)
- [Prompt Injection](https://learnprompting.org/docs/prompt_hacking/injection)

===